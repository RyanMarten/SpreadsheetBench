name: Parity Experiments (Exp 1 + 2)

on:
  workflow_dispatch:
    inputs:
      num_trials:
        description: 'Number of inference trials'
        required: false
        default: '3'
        type: string
      dataset:
        description: 'Dataset to use'
        required: false
        default: 'spreadsheetbench_verified_400'
        type: string
      limit:
        description: 'Limit number of tasks (0 = all)'
        required: false
        default: '0'
        type: string

jobs:
  inference:
    name: LLM Inference (Haiku 4.5)
    runs-on: ubuntu-latest
    strategy:
      matrix:
        trial: ${{ fromJSON(format('[{0}]', join(fromJSON(format('["{0}"]', inputs.num_trials == '1' && '1' || inputs.num_trials == '2' && '1","2' || '1","2","3')), ','))) }}
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Extract dataset
        run: |
          cd data
          if [ ! -d "${{ inputs.dataset }}" ]; then
            tar xzf "${{ inputs.dataset }}.tar.gz"
          fi

      - name: Build code execution Docker image
        run: |
          cd code_exec_docker
          docker build -f Dockerfile.executor -t ssb-executor .

      - name: Start Jupyter kernel
        run: |
          cd code_exec_docker
          # Update config to point to the right dataset
          python -c "
          import json
          config = json.load(open('config.json'))
          config['DATA_DIR'] = '../data/${{ inputs.dataset }}'
          json.dump(config, open('config.json', 'w'))
          "
          bash start_jupyter_server.sh 8888 &
          sleep 10

      - name: Start API server
        run: |
          cd code_exec_docker
          docker build -f Dockerfile.api -t ssb-api .
          docker run -d -p 8081:8081 \
            -v "$(pwd)/../data:/mnt/data" \
            -e JUPYTER_URL=http://host.docker.internal:8888 \
            ssb-api
          sleep 5

      - name: Run inference (Trial ${{ matrix.trial }})
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          cd inference
          LIMIT_ARG=""
          if [ "${{ inputs.limit }}" != "0" ]; then
            LIMIT_ARG="--limit ${{ inputs.limit }}"
          fi
          python inference_single.py \
            --model claude-haiku-4-5-20251001 \
            --api_key "$ANTHROPIC_API_KEY" \
            --base_url "https://api.anthropic.com/v1/" \
            --dataset "${{ inputs.dataset }}" \
            --num-test-cases 1 \
            --conv_id "trial${{ matrix.trial }}"

      - name: Upload inference outputs
        uses: actions/upload-artifact@v4
        with:
          name: inference-outputs-trial${{ matrix.trial }}
          path: |
            data/${{ inputs.dataset }}/outputs/single_claude-haiku-4-5-20251001/
            inference/outputs/conv_single_claude-haiku-4-5-20251001.jsonl

      - name: Upload dataset JSON
        if: matrix.trial == '1'
        uses: actions/upload-artifact@v4
        with:
          name: dataset-json
          path: data/${{ inputs.dataset }}/dataset.json

  eval-libreoffice:
    name: LibreOffice Evaluation (Exp 2)
    needs: inference
    runs-on: ubuntu-latest
    strategy:
      matrix:
        trial: ${{ fromJSON(format('[{0}]', join(fromJSON(format('["{0}"]', inputs.num_trials == '1' && '1' || inputs.num_trials == '2' && '1","2' || '1","2","3')), ','))) }}
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          sudo apt-get update
          sudo apt-get install -y libreoffice-calc

      - name: Extract dataset
        run: |
          cd data
          if [ ! -d "${{ inputs.dataset }}" ]; then
            tar xzf "${{ inputs.dataset }}.tar.gz"
          fi

      - name: Download inference outputs
        uses: actions/download-artifact@v4
        with:
          name: inference-outputs-trial${{ matrix.trial }}
          path: data/${{ inputs.dataset }}/outputs/single_claude-haiku-4-5-20251001/

      - name: Recalculate formulas (LibreOffice)
        run: |
          bash evaluation/recalculate_libreoffice.sh \
            "data/${{ inputs.dataset }}/outputs/single_claude-haiku-4-5-20251001/"

      - name: Recalculate answer file formulas (LibreOffice)
        run: |
          # Recalculate answer/golden files too
          bash evaluation/recalculate_libreoffice.sh \
            "data/${{ inputs.dataset }}/spreadsheet/" --recursive

      - name: Run evaluation
        run: |
          cd evaluation
          python evaluation.py \
            --model claude-haiku-4-5-20251001 \
            --setting single \
            --dataset "${{ inputs.dataset }}" \
            --num-test-cases 1

      - name: Upload evaluation results
        uses: actions/upload-artifact@v4
        with:
          name: eval-libreoffice-trial${{ matrix.trial }}
          path: outputs/eval_single_claude-haiku-4-5-20251001.json

      - name: Print summary
        run: |
          python -c "
          import json
          results = json.load(open('outputs/eval_single_claude-haiku-4-5-20251001.json'))
          soft = [r['soft_restriction'] for r in results]
          hard = [r['hard_restriction'] for r in results]
          print(f'Trial ${{ matrix.trial }} (LibreOffice):')
          print(f'  Soft pass rate: {sum(soft)/len(soft)*100:.2f}%')
          print(f'  Hard pass rate: {sum(hard)/len(hard)*100:.2f}%')
          print(f'  Total tasks: {len(results)}')
          "

  eval-win32com:
    name: Win32com Evaluation (Exp 1)
    needs: inference
    runs-on: windows-latest
    strategy:
      matrix:
        trial: ${{ fromJSON(format('[{0}]', join(fromJSON(format('["{0}"]', inputs.num_trials == '1' && '1' || inputs.num_trials == '2' && '1","2' || '1","2","3')), ','))) }}
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pywin32

      - name: Extract dataset
        run: |
          cd data
          tar xzf "${{ inputs.dataset }}.tar.gz"

      - name: Download inference outputs
        uses: actions/download-artifact@v4
        with:
          name: inference-outputs-trial${{ matrix.trial }}
          path: data/${{ inputs.dataset }}/outputs/single_claude-haiku-4-5-20251001/

      - name: Recalculate formulas (win32com + Excel)
        run: |
          python evaluation/open_spreadsheet.py \
            --dir_path "data/${{ inputs.dataset }}/outputs/single_claude-haiku-4-5-20251001/" \
            --backend win32com

      - name: Recalculate answer file formulas
        run: |
          # Process each spreadsheet subdirectory
          $dirs = Get-ChildItem -Path "data/${{ inputs.dataset }}/spreadsheet/" -Directory
          foreach ($dir in $dirs) {
            python evaluation/open_spreadsheet.py --dir_path $dir.FullName --backend win32com
          }
        shell: pwsh

      - name: Run evaluation
        run: |
          cd evaluation
          python evaluation.py \
            --model claude-haiku-4-5-20251001 \
            --setting single \
            --dataset "${{ inputs.dataset }}" \
            --num-test-cases 1

      - name: Upload evaluation results
        uses: actions/upload-artifact@v4
        with:
          name: eval-win32com-trial${{ matrix.trial }}
          path: outputs/eval_single_claude-haiku-4-5-20251001.json

      - name: Print summary
        run: |
          python -c "
          import json
          results = json.load(open('outputs/eval_single_claude-haiku-4-5-20251001.json'))
          soft = [r['soft_restriction'] for r in results]
          hard = [r['hard_restriction'] for r in results]
          print(f'Trial ${{ matrix.trial }} (Win32com):')
          print(f'  Soft pass rate: {sum(soft)/len(soft)*100:.2f}%')
          print(f'  Hard pass rate: {sum(hard)/len(hard)*100:.2f}%')
          print(f'  Total tasks: {len(results)}')
          "

  summary:
    name: Parity Summary
    needs: [eval-libreoffice, eval-win32com]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Download all eval results
        uses: actions/download-artifact@v4
        with:
          pattern: eval-*
          path: results/

      - name: Generate parity report
        run: |
          python3 -c "
          import json, os, glob

          print('=== Parity Experiment Results ===')
          print()

          for backend in ['libreoffice', 'win32com']:
            files = sorted(glob.glob(f'results/eval-{backend}-trial*/eval_single_*.json'))
            if not files:
              print(f'{backend}: No results found')
              continue
            print(f'{backend.upper()} Evaluation:')
            for f in files:
              trial = f.split('trial')[1].split('/')[0]
              results = json.load(open(f))
              soft = [r['soft_restriction'] for r in results]
              hard = [r['hard_restriction'] for r in results]
              print(f'  Trial {trial}: soft={sum(soft)/len(soft)*100:.2f}%, hard={sum(hard)/len(hard)*100:.2f}%, n={len(results)}')
            print()
          "
